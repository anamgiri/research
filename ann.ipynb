{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e09e418-eb4c-48f8-84a2-d67bc03f4dd4",
   "metadata": {},
   "source": [
    " import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import pytz\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9198e5af-e417-46f8-9572-c78eab3d8889",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import pytz\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bfa13f4-0894-4e4e-a64d-82270d31e519",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"pm25_cleaned_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "554829db-80b2-42dc-9359-91f200229c03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28325, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "877ef735-8fa3-402f-91cb-3790b0b74161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utc</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-03-12T18:15:00+00:00</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-03-12T17:15:00+00:00</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-03-12T16:15:00+00:00</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-03-12T15:15:00+00:00</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-03-12T14:15:00+00:00</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         utc  value\n",
       "0  2021-03-12T18:15:00+00:00   69.0\n",
       "1  2021-03-12T17:15:00+00:00   69.0\n",
       "2  2021-03-12T16:15:00+00:00   60.0\n",
       "3  2021-03-12T15:15:00+00:00   58.0\n",
       "4  2021-03-12T14:15:00+00:00   58.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9ae9e8b-70cf-4407-b370-18f81ce011f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 18974\n",
      "Validation size: 7859\n",
      "Test size: 1518\n"
     ]
    }
   ],
   "source": [
    "# Define the split dates\n",
    "train_end = '2019-12-31'\n",
    "val_end = '2020-12-31'\n",
    "\n",
    "# Assuming your DataFrame has a column 'date' with date values\n",
    "df['utc'] = pd.to_datetime(df['utc'])\n",
    "df.set_index('utc', inplace=True)\n",
    "df.sort_index(inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Split the data\n",
    "y_train = df[:train_end]  # Data up to the end of 2019\n",
    "y_val = df[train_end:val_end]  # Data from 2020\n",
    "y_test = df[val_end:]  # Data from 2021 onward\n",
    "\n",
    "# Print the sizes to confirm\n",
    "print(f\"Train size: {len(y_train)}\")\n",
    "print(f\"Validation size: {len(y_val)}\")\n",
    "print(f\"Test size: {len(y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e129a992-6e5b-497f-ba1e-b1fbc455b050",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"  # Disable GPU usage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fd79d9-a2c3-4acb-bef6-f6d863ac8e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-26 19:50:05.868672: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1\n",
      "2024-12-26 19:50:05.868698: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
      "2024-12-26 19:50:05.868702: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
      "2024-12-26 19:50:05.868903: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-12-26 19:50:05.868913: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "\n",
    "\n",
    "# Create lag features (you can change the number of lags as needed)\n",
    "lag = 2\n",
    "for i in range(1, lag + 1):\n",
    "    df[f'lag_{i}'] = df['value'].shift(i)\n",
    "df.dropna(inplace=True)  # Remove NaN values from lagging\n",
    "\n",
    "# Split into train, validation, and test sets (replace with actual dates)\n",
    "train_end = '2019-12-31'\n",
    "val_end = '2020-12-31'\n",
    "\n",
    "X_train = df[:train_end].drop('value', axis=1)  # Features for training\n",
    "y_train = df[:train_end]['value']  # Target for training\n",
    "\n",
    "X_val = df[train_end:val_end].drop('value', axis=1)  # Features for validation\n",
    "y_val = df[train_end:val_end]['value']  # Target for validation\n",
    "\n",
    "X_test = df[val_end:].drop('value', axis=1)  # Features for test\n",
    "y_test = df[val_end:]['value']  # Target for test\n",
    "\n",
    "# Normalize features\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    Input(shape=(X_train_scaled.shape[1],)),  # Input layer\n",
    "    Dense(64, activation='relu'),  # Hidden Layer 1\n",
    "    Dense(32, activation='relu'),  # Hidden Layer 2\n",
    "    Dense(1)  # Output Layer\n",
    "])\n",
    "\n",
    "# Compile and train the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "history = model.fit(X_train_scaled, y_train, validation_data=(X_val_scaled, y_val), epochs=50, batch_size=32, verbose=1)\n",
    "\n",
    "# Predictions and Evaluation\n",
    "y_pred = model.predict(X_val_scaled)\n",
    "mae = mean_absolute_error(y_val, y_pred)\n",
    "mse = mean_squared_error(y_val, y_pred)\n",
    "\n",
    "print(f'Validation MAE: {mae}')\n",
    "print(f'Validation MSE: {mse}')\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_test_pred = model.predict(X_test_scaled)\n",
    "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "print(f'Test MAE: {test_mae}')\n",
    "print(f'Test MSE: {test_mse}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f94c27-d503-4f41-908c-c87973e0bbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_lag_features(df, lag=3):\n",
    "    for i in range(1, lag + 1):\n",
    "        df[f'lag_{i}'] = df[0].shift(i)\n",
    "    df.dropna(inplace=True)\n",
    "    return df.iloc[:, 1:], df.iloc[:, 0]  # Features (lags), Target (current)\n",
    "\n",
    "X, y = create_lag_features(y_train, lag=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de186a4a-868a-44dd-b16f-aa119549a1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rolling forecast for test set\n",
    "predictions = []\n",
    "history = list(y_train)  # Start with training data\n",
    "\n",
    "for t in range(len(y_test)):\n",
    "    lag_features = np.array(history[-3:]).reshape(1, -1)  # Last 3 values\n",
    "    lag_features_scaled = scaler.transform(lag_features)\n",
    "    \n",
    "    next_prediction = model.predict(lag_features_scaled)\n",
    "    next_prediction = scaler.inverse_transform(next_prediction)  # Rescale prediction\n",
    "    predictions.append(next_prediction[0, 0])\n",
    "    \n",
    "    # Update history with actual test value\n",
    "    history.append(y_test.iloc[t])\n",
    "\n",
    "# Convert predictions to a series\n",
    "predictions_series = pd.Series(predictions, index=y_test.index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_env)",
   "language": "python",
   "name": "tf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
